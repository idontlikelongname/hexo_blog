<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.yangxiaoxiao.net.cn","root":"/","scheme":"Gemini","version":"7.7.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":false,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Awesome系列Awesome Autonomous Vehicle自动驾驶相关的资源的收集汇总，包括课程、实验室、数据集、SOTA代码、软件、硬件等 Awesome Point Cloud Analysis3D Object Detectionpapers and code related to 3D object detection Awesome NN SLAMSLAM algorithm">
<meta property="og:type" content="article">
<meta property="og:title" content="Awesome Automative Driving Perception">
<meta property="og:url" content="http://www.yangxiaoxiao.net.cn/2020/02/25/Awesome-Automative-Driving-Perception/index.html">
<meta property="og:site_name" content="路上捡个大西瓜">
<meta property="og:description" content="Awesome系列Awesome Autonomous Vehicle自动驾驶相关的资源的收集汇总，包括课程、实验室、数据集、SOTA代码、软件、硬件等 Awesome Point Cloud Analysis3D Object Detectionpapers and code related to 3D object detection Awesome NN SLAMSLAM algorithm">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://www.yangxiaoxiao.net.cn/images/Awesome-Automative-Driving-Perception/Ford_AVDataset.jpg">
<meta property="article:published_time" content="2020-02-25T06:49:02.000Z">
<meta property="article:modified_time" content="2020-05-06T07:03:08.351Z">
<meta property="article:author" content="Xiaoxiao Yang">
<meta property="article:tag" content="感知">
<meta property="article:tag" content="Awesome">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://www.yangxiaoxiao.net.cn/images/Awesome-Automative-Driving-Perception/Ford_AVDataset.jpg">

<link rel="canonical" href="http://www.yangxiaoxiao.net.cn/2020/02/25/Awesome-Automative-Driving-Perception/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>Awesome Automative Driving Perception | 路上捡个大西瓜</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>
    <a href="https://github.com/idontlikelongname" target="_blank" rel="noopener" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">路上捡个大西瓜</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.yangxiaoxiao.net.cn/2020/02/25/Awesome-Automative-Driving-Perception/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Xiaoxiao Yang">
      <meta itemprop="description" content="DuDuBiu的个人小站">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="路上捡个大西瓜">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          Awesome Automative Driving Perception
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-25 06:49:02" itemprop="dateCreated datePublished" datetime="2020-02-25T06:49:02+00:00">2020-02-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-05-06 07:03:08" itemprop="dateModified" datetime="2020-05-06T07:03:08+00:00">2020-05-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Awesome/" itemprop="url" rel="index">
                    <span itemprop="name">Awesome</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="Awesome系列"><a href="#Awesome系列" class="headerlink" title="Awesome系列"></a><strong>Awesome系列</strong></h3><h4 id="Awesome-Autonomous-Vehicle"><a href="#Awesome-Autonomous-Vehicle" class="headerlink" title="Awesome Autonomous Vehicle"></a><a href="https://github.com/DeepTecher/awesome-autonomous-vehicle" target="_blank" rel="noopener">Awesome Autonomous Vehicle</a></h4><p>自动驾驶相关的资源的收集汇总，包括课程、实验室、数据集、SOTA代码、软件、硬件等</p>
<h4 id="Awesome-Point-Cloud-Analysis"><a href="#Awesome-Point-Cloud-Analysis" class="headerlink" title="Awesome Point Cloud Analysis"></a><a href="https://github.com/Yochengliu/awesome-point-cloud-analysis" target="_blank" rel="noopener">Awesome Point Cloud Analysis</a></h4><h4 id="3D-Object-Detection"><a href="#3D-Object-Detection" class="headerlink" title="3D Object Detection"></a><a href="https://github.com/Yvanali/3D-Object-Detection" target="_blank" rel="noopener">3D Object Detection</a></h4><p>papers and code related to 3D object detection</p>
<h4 id="Awesome-NN-SLAM"><a href="#Awesome-NN-SLAM" class="headerlink" title="Awesome NN SLAM"></a><a href="https://github.com/UltronAI/awesome-nn-slam" target="_blank" rel="noopener">Awesome NN SLAM</a></h4><p>SLAM algorithm and systems based on Neural Networks</p>
<hr>
<h3 id="3D-Detection-base-on-Lidar"><a href="#3D-Detection-base-on-Lidar" class="headerlink" title="3D Detection base on Lidar"></a><strong>3D Detection base on Lidar</strong></h3><h4 id="PointPillars"><a href="#PointPillars" class="headerlink" title="PointPillars"></a><a href="https://github.com/traveller59/second.pytorch" target="_blank" rel="noopener">PointPillars</a><br></h4><h4 id="PointPillars-Fast-Encoders-for-Object-Detection-from-Point-Clouds"><a href="#PointPillars-Fast-Encoders-for-Object-Detection-from-Point-Clouds" class="headerlink" title="PointPillars: Fast Encoders for Object Detection from Point Clouds"></a><a href="https://arxiv.org/abs/1812.05784" target="_blank" rel="noopener">PointPillars: Fast Encoders for Object Detection from Point Clouds</a></h4><p>原版PointPillars网络实现，nuTonomy公司实现的3D目标检测网络</p>
<h4 id="Det3D"><a href="#Det3D" class="headerlink" title="Det3D"></a><a href="https://github.com/poodarchu/Det3D" target="_blank" rel="noopener">Det3D</a></h4><p>3D目标检测框架，包括PointPillars Second算法，KITTI NuScenes Lyft数据集，包括很多点云预处理的方法</p>
<h4 id="points3d"><a href="#points3d" class="headerlink" title="points3d"></a><a href="https://github.com/nicolas-chaulet/torch-points3d" target="_blank" rel="noopener">points3d</a></h4><p>Pytorch framework for doing deep learning on point clouds</p>
<h4 id="PointRCNN"><a href="#PointRCNN" class="headerlink" title="PointRCNN"></a><a href="https://github.com/sshaoshuai/PointRCNN" target="_blank" rel="noopener">PointRCNN</a><br></h4><p>CVPR2019，3D目标检测，Two Stage检测，先前后背景分割，然后提取3D框</p>
<h4 id="PointNet系列"><a href="#PointNet系列" class="headerlink" title="PointNet系列"></a><strong>PointNet系列</strong></h4><h4 id="PointNet"><a href="#PointNet" class="headerlink" title="PointNet"></a><a href="https://github.com/yanx27/Pointnet_Pointnet2_pytorch" target="_blank" rel="noopener">PointNet</a></h4><p>CVPR2016，3D点云的特征提取网络，能够作为分类，分割网络的主干网络使用<br><a href="https://medium.com/@luis_gonzales/an-in-depth-look-at-pointnet-111d7efdaa1a" target="_blank" rel="noopener">论文解读</a></p>
<h4 id="PointNet-1"><a href="#PointNet-1" class="headerlink" title="PointNet++"></a><a href="https://github.com/yanx27/Pointnet_Pointnet2_pytorch" target="_blank" rel="noopener">PointNet++</a></h4><p>CVPR2017，PointNet改进版，提高了对于点云局部特征的提取能力</p>
<h4 id="PointNet-for-ScanNet"><a href="#PointNet-for-ScanNet" class="headerlink" title="PointNet++ for ScanNet"></a><a href="https://github.com/daveredrum/Pointnet2.ScanNet" target="_blank" rel="noopener">PointNet++ for ScanNet</a></h4><p>PointNet++分割网络实现</p>
<h4 id="TANet"><a href="#TANet" class="headerlink" title="TANet"></a><a href="https://github.com/happinesslz/TANet" target="_blank" rel="noopener">TANet</a></h4><p>对PointPillars进行改进，加入Triple Attention(?)，提高了网络检测性能，3D检测置信度提高了</p>
<h4 id="PIXOR"><a href="#PIXOR" class="headerlink" title="PIXOR"></a><a href="https://github.com/philip-huang/PIXOR" target="_blank" rel="noopener">PIXOR</a></h4><h4 id="Complex-YOLO"><a href="#Complex-YOLO" class="headerlink" title="Complex-YOLO"></a><a href="https://github.com/AI-liu/Complex-YOLO" target="_blank" rel="noopener">Complex-YOLO</a></h4><h4 id="3D-IoU-Net"><a href="#3D-IoU-Net" class="headerlink" title="3D IoU-Net"></a><a href="https://arxiv.org/abs/2004.04962" target="_blank" rel="noopener">3D IoU-Net</a></h4><h4 id="3DSSD"><a href="#3DSSD" class="headerlink" title="3DSSD"></a><a href="https://github.com/Jia-Research-Lab/3DSSD" target="_blank" rel="noopener">3DSSD</a></h4><p>Point-based 3D Single Stage Object Detector</p>
<h4 id="SSN"><a href="#SSN" class="headerlink" title="SSN"></a><a href="https://github.com/xinge008/SSN" target="_blank" rel="noopener">SSN</a></h4><p>SSN: Shape Signature Networks for Multi-class Object Detection from Point Clouds</p>
<h4 id="SA-SSD"><a href="#SA-SSD" class="headerlink" title="SA-SSD"></a><a href="https://github.com/skyhehe123/SA-SSD" target="_blank" rel="noopener">SA-SSD</a></h4><p>SOTA, SA-SSD: Structure Aware Single-stage 3D Object Detection from Point Cloud </p>
<h4 id="PV-RCNN"><a href="#PV-RCNN" class="headerlink" title="PV-RCNN"></a><a href="https://github.com/sshaoshuai/PV-RCNN" target="_blank" rel="noopener">PV-RCNN</a></h4><p>CVPR 2020 paper PointVoxel-RCNN for 3D object detection from point cloud.</p>
<h3 id="3D-Detection-base-on-Camera"><a href="#3D-Detection-base-on-Camera" class="headerlink" title="3D Detection base on Camera"></a><strong>3D Detection base on Camera</strong></h3><h4 id="3D-Detection"><a href="#3D-Detection" class="headerlink" title="3D Detection"></a><a href="https://github.com/tom-roddick/oft" target="_blank" rel="noopener">3D Detection</a></h4><h4 id="单目3D检测Mono3D"><a href="#单目3D检测Mono3D" class="headerlink" title="单目3D检测Mono3D++"></a><a href="https://www.arxiv-vanity.com/papers/1901.03912/" target="_blank" rel="noopener">单目3D检测Mono3D++</a></h4><h4 id="Orthographic-3D-Object-Detection"><a href="#Orthographic-3D-Object-Detection" class="headerlink" title="Orthographic 3D Object Detection"></a><a href="https://github.com/tom-roddick/oft" target="_blank" rel="noopener">Orthographic 3D Object Detection</a></h4><h4 id="TLNet"><a href="#TLNet" class="headerlink" title="TLNet"></a><a href="https://github.com/Zengyi-Qin/TLNet" target="_blank" rel="noopener">TLNet</a></h4><p>Triangulation Learning Network: from Monocular to Stereo 3D Object Detection</p>
<h4 id="SMOKE"><a href="#SMOKE" class="headerlink" title="SMOKE"></a><a href="https://github.com/lzccccc/SMOKE" target="_blank" rel="noopener">SMOKE</a></h4><p>Single-Stage Monocular 3D Object Detection via Keypoint Estimation</p>
<hr>
<h3 id="2D-Detection"><a href="#2D-Detection" class="headerlink" title="2D Detection"></a><strong>2D Detection</strong></h3><h4 id="mmdetection"><a href="#mmdetection" class="headerlink" title="mmdetection"></a><a href="https://github.com/open-mmlab/mmdetection" target="_blank" rel="noopener">mmdetection</a></h4><p>商汤开源的目标检测框架，实现了多种目标检测算法</p>
<h4 id="SimpleDet"><a href="#SimpleDet" class="headerlink" title="SimpleDet"></a><a href="https://github.com/tusimple/simpledet" target="_blank" rel="noopener">SimpleDet</a></h4><p>图森开源的简单、可拓展性强的目标检测和实例分割的框架，包括FPN CascadeRCNN RetinaNet TridentNet MaskRCNN EfficientNet FCOS RepPoint</p>
<h4 id="CenterNet"><a href="#CenterNet" class="headerlink" title="CenterNet"></a>CenterNet</h4><p><a href="https://github.com/FateScript/CenterNet-better" target="_blank" rel="noopener">实现1</a><br><a href="https://github.com/bleakie/CenterMulti" target="_blank" rel="noopener">实现2</a><br>没有训练部分，带TensorRT</p>
<h4 id="ShuffleNet"><a href="#ShuffleNet" class="headerlink" title="ShuffleNet"></a><a href="https://github.com/megvii-model/ShuffleNet-Series" target="_blank" rel="noopener">ShuffleNet</a></h4><p>ShuffleNet实现系列</p>
<h4 id="DenseBox"><a href="#DenseBox" class="headerlink" title="DenseBox"></a><a href="https://github.com/CaptainEven/DenseBox" target="_blank" rel="noopener">DenseBox</a></h4><h4 id="EfficientDet"><a href="#EfficientDet" class="headerlink" title="EfficientDet"></a><a href="https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch" target="_blank" rel="noopener">EfficientDet</a></h4><h4 id="SSD系列"><a href="#SSD系列" class="headerlink" title="SSD系列"></a>SSD系列</h4><p><a href="https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection" target="_blank" rel="noopener">SSD</a><br><a href="https://francescopochetti.com/fast-ai-dl2-lesson-9-single-shot-detection-detailed-walkthrough/" target="_blank" rel="noopener">SSD教程</a><br><a href="https://github.com/lzx1413/PytorchSSD" target="_blank" rel="noopener">SSD Pytorch实现</a><br><a href="https://github.com/qfgaohao/pytorch-ssd" target="_blank" rel="noopener">SSD Pytorch实现2</a><br><a href="https://github.com/lufficc/SSD" target="_blank" rel="noopener">SSD Pytorch实现3</a></p>
<h4 id="YOLOv3系列"><a href="#YOLOv3系列" class="headerlink" title="YOLOv3系列"></a>YOLOv3系列</h4><p><a href="https://github.com/westerndigitalcorporation/YOLOv3-in-PyTorch" target="_blank" rel="noopener">pytorch实现1</a><br><a href="https://github.com/amusi/YOLO-Reproduce-Summary#PyTorch" target="_blank" rel="noopener">YOLOv3各种框架复现汇总</a><br><a href="https://github.com/wlguan/Stronger-yolo-pytorch" target="_blank" rel="noopener">Stronger性能增强版YOLOv3</a><br><a href="https://github.com/coldlarry/YOLOv3-complete-pruning" target="_blank" rel="noopener">剪纸量化版YOLOv3</a><br><a href="https://github.com/jwchoi384/Gaussian_YOLOv3" target="_blank" rel="noopener">Gaussian YOLOv3</a><br><a href="https://arxiv.org/pdf/1910.01271.pdf" target="_blank" rel="noopener">YOLO Nano</a><br><a href="https://github.com/PengyiZhang/SlimYOLOv3" target="_blank" rel="noopener">SlimYOLOv3</a></p>
<hr>
<h3 id="Segmentation"><a href="#Segmentation" class="headerlink" title="Segmentation"></a><strong>Segmentation</strong></h3><h4 id="Pytorch-Segmentation"><a href="#Pytorch-Segmentation" class="headerlink" title="Pytorch Segmentation"></a><a href="">Pytorch Segmentation</a></h4><p>Pytorch实现的语义分割模型集<br>Fast SCNN, HRNet, Deeplabv3_plus, ContextNet, FPENet, DABNet, EdaNet, ENet, Espnetv2, RefineNet, UNet, DANet,PSPNet, ICNet, FCN, deeplab</p>
<h4 id="Pytorch-Segmentation-Efficient"><a href="#Pytorch-Segmentation-Efficient" class="headerlink" title="Pytorch Segmentation-Efficient"></a><a href="https://github.com/xiaoyufenfei/Efficient-Segmentation-Networks" target="_blank" rel="noopener">Pytorch Segmentation-Efficient</a></h4><p>pytorch轻量语义分割实现集锦</p>
<h4 id="Pytorch-Segmentation-Fast"><a href="#Pytorch-Segmentation-Fast" class="headerlink" title="Pytorch Segmentation-Fast"></a><a href="https://github.com/lxtGH/Fast_Seg" target="_blank" rel="noopener">Pytorch Segmentation-Fast</a></h4><p>CityScape Mapillary Camvid数据集的分割网络集锦，主要集中在道路图像</p>
<h4 id="Pytorch-Segmentation-Toolbox"><a href="#Pytorch-Segmentation-Toolbox" class="headerlink" title="Pytorch Segmentation Toolbox"></a><a href="https://github.com/Media-Smart/vedaseg" target="_blank" rel="noopener">Pytorch Segmentation Toolbox</a></h4><p>DeepLabv2Plus, FPN, PSPNet U-Net</p>
<h4 id="Pytorch-Segmentation-1"><a href="#Pytorch-Segmentation-1" class="headerlink" title="Pytorch Segmentation"></a><a href="https://github.com/yassouali/pytorch_segmentation" target="_blank" rel="noopener">Pytorch Segmentation</a></h4><p>各种分割网络的实现</p>
<h4 id="Pytorch-Segmentation-2"><a href="#Pytorch-Segmentation-2" class="headerlink" title="Pytorch Segmentation"></a><a href="https://github.com/guanfuchen/semseg" target="_blank" rel="noopener">Pytorch Segmentation</a></h4><p>常用语义分割框架结构，数据集加载模块</p>
<h4 id="Learning-Semantic-Boundaries-from-Noisy-Annotations"><a href="#Learning-Semantic-Boundaries-from-Noisy-Annotations" class="headerlink" title="Learning Semantic Boundaries from Noisy Annotations"></a><a href="https://github.com/nv-tlabs/STEAL" target="_blank" rel="noopener">Learning Semantic Boundaries from Noisy Annotations</a></h4><p>CVPR2019,可以用在Kinect人像分割</p>
<h4 id="LEDNet"><a href="#LEDNet" class="headerlink" title="LEDNet"></a><a href="https://github.com/xiaoyufenfei/LEDNet" target="_blank" rel="noopener">LEDNet</a></h4><p>2019，轻量级图像分割网络，可以达到70FPS</p>
<h4 id="Fast-SCNN"><a href="#Fast-SCNN" class="headerlink" title="Fast-SCNN"></a><a href="https://github.com/DeepVoltaire/Fast-SCNN" target="_blank" rel="noopener">Fast-SCNN</a></h4><p>Real-time Semantic Segmentation</p>
<h4 id="U-Net"><a href="#U-Net" class="headerlink" title="U-Net"></a><a href="https://medium.com/analytics-vidhya/u-net-engineering-5a84ee193aaf" target="_blank" rel="noopener">U-Net</a></h4><p>U-Net改进、性能提高方法</p>
<h4 id="YOLACT"><a href="#YOLACT" class="headerlink" title="YOLACT"></a><a href="https://github.com/dbolya/yolact" target="_blank" rel="noopener">YOLACT</a></h4><p>ICCV2019,简单高效的实时实例分割模型</p>
<h4 id="CenterMask"><a href="#CenterMask" class="headerlink" title="CenterMask"></a><a href="https://arxiv.org/abs/2004.04446" target="_blank" rel="noopener">CenterMask</a></h4><p>CenterMask: single shot instance segmentation with point representation</p>
<p><a href="https://arxiv.org/abs/1901.06580" target="_blank" rel="noopener">自动驾驶实时语义分割</a><br><a href="https://www.arxiv-vanity.com/papers/1901.03912/" target="_blank" rel="noopener">自动驾驶目标检测与分割多任务网络</a></p>
<p><a href="https://github.com/amusi/awesome-lane-detection" target="_blank" rel="noopener">车道线Awesome</a></p>
<p><a href="https://github.com/nianticlabs/footprints" target="_blank" rel="noopener">FootPrints</a><br>Footprints and Free Space from a Single Color Image</p>
<p><a href="https://neptune.ai/blog/image-segmentation-in-2020" target="_blank" rel="noopener">2020 Segmentation Reviews</a></p>
<hr>
<h3 id="Backbone"><a href="#Backbone" class="headerlink" title="Backbone"></a><strong>Backbone</strong></h3><h4 id="VoVNet"><a href="#VoVNet" class="headerlink" title="VoVNet"></a><a href="https://github.com/stigma0617/VoVNet.pytorch" target="_blank" rel="noopener">VoVNet</a></h4><p>高效的主干网络，适合GPU，速度比ResNet快30%</p>
<hr>
<h3 id="Tracking"><a href="#Tracking" class="headerlink" title="Tracking"></a><strong>Tracking</strong></h3><h4 id="3D-Mutli-Object-Tracking"><a href="#3D-Mutli-Object-Tracking" class="headerlink" title="3D Mutli-Object Tracking"></a><a href="https://github.com/eddyhkchiu/mahalanobis_3d_multi_object_tracking" target="_blank" rel="noopener">3D Mutli-Object Tracking</a></h4><p>NeurIPS 2019 Workshop, 3D Tracking for Autonomous Driving,NuScene数据集</p>
<h4 id="Argo-Baseline-Tracking"><a href="#Argo-Baseline-Tracking" class="headerlink" title="Argo Baseline Tracking"></a><a href="https://github.com/alliecc/argoverse_baselinetracker/tree/master/pykitti" target="_blank" rel="noopener">Argo Baseline Tracking</a></h4><p>Argo Dataset官方tracking baseline</p>
<h4 id="DeepSort"><a href="#DeepSort" class="headerlink" title="DeepSort"></a><a href="https://github.com/ZQPei/deep_sort_pytorch" target="_blank" rel="noopener">DeepSort</a></h4><h4 id="Multi-Object-Tracking"><a href="#Multi-Object-Tracking" class="headerlink" title="Multi Object Tracking"></a><a href="https://github.com/selflein/GraphNN-Multi-Object-Tracking" target="_blank" rel="noopener">Multi Object Tracking</a></h4><p>Multi Object Tracking using Graph Neural Networks</p>
<h4 id="Multi-Object-Tracking-in-Python-and-Pytorch"><a href="#Multi-Object-Tracking-in-Python-and-Pytorch" class="headerlink" title="Multi-Object Tracking in Python and Pytorch"></a><a href="https://github.com/nightmaredimple/libmot" target="_blank" rel="noopener">Multi-Object Tracking in Python and Pytorch</a></h4><p>A Library of Multi-Object Tracking in Python and Pytorch</p>
<h4 id="FairMOT"><a href="#FairMOT" class="headerlink" title="FairMOT"></a><a href="https://github.com/ifzhang/FairMOT" target="_blank" rel="noopener">FairMOT</a></h4><p>A simple baseline for one-shot multi-object tracking, re-identification</p>
<h4 id="Object-Detection-and-Tracking"><a href="#Object-Detection-and-Tracking" class="headerlink" title="Object-Detection-and-Tracking"></a><a href="https://github.com/yehengchen/Object-Detection-and-Tracking" target="_blank" rel="noopener">Object-Detection-and-Tracking</a></h4><p>YOLO &amp; RCNN Object Detection and Multi-Object Tracking</p>
<h4 id="SDVTracker"><a href="#SDVTracker" class="headerlink" title="SDVTracker"></a><a href="https://arxiv.org/abs/2003.04447" target="_blank" rel="noopener">SDVTracker</a></h4><p>SDVTracker: Real-Time Multi-Sensor Association and Tracking for Self-Driving Vehicles</p>
<hr>
<h3 id="Prediction"><a href="#Prediction" class="headerlink" title="Prediction"></a><strong>Prediction</strong></h3><h4 id="MotionNet"><a href="#MotionNet" class="headerlink" title="MotionNet"></a><a href="https://github.com/pxiangwu/MotionNet" target="_blank" rel="noopener">MotionNet</a></h4><p>MotionNet: Joint Perception and Motion Prediction for Autonomous Driving Based on Bird’s Eye View Maps</p>
<hr>
<h3 id="SLAM"><a href="#SLAM" class="headerlink" title="SLAM"></a><strong>SLAM</strong></h3><h4 id="Point-Cloud-Registration"><a href="#Point-Cloud-Registration" class="headerlink" title="Point Cloud Registration"></a><a href="https://github.com/MIT-SPARK/TEASER-plusplus" target="_blank" rel="noopener">Point Cloud Registration</a></h4><p>点云帧间匹配</p>
<h4 id="DeLS-3D"><a href="#DeLS-3D" class="headerlink" title="DeLS-3D"></a><a href="https://github.com/pengwangucla/DeLS-3D" target="_blank" rel="noopener">DeLS-3D</a></h4><p>CVPR2018， Deep Localization and Segmentation with a 3D Semantic Map</p>
<h4 id="NDT改进"><a href="#NDT改进" class="headerlink" title="NDT改进"></a><a href="https://github.com/OrebroUniversity/perception_oru-release/tree/debian/groovy/oneiric/ndt_registration" target="_blank" rel="noopener">NDT改进</a></h4><p>实验室代码仓库，改进了很多种算法</p>
<h4 id="SuMa"><a href="#SuMa" class="headerlink" title="SuMa++"></a><a href="https://github.com/PRBonn/semantic_suma" target="_blank" rel="noopener">SuMa++</a></h4><p>一种点云语义SLAM，可视化界面值得借鉴</p>
<h4 id="BLAM"><a href="#BLAM" class="headerlink" title="BLAM"></a><a href="https://github.com/erik-nelson/blam" target="_blank" rel="noopener">BLAM</a></h4><p>SLAM Project launched by Berkeley Member</p>
<h4 id="SE3SLAM"><a href="#SE3SLAM" class="headerlink" title="SE3SLAM"></a><a href="https://github.com/izhengfan/se2clam" target="_blank" rel="noopener">SE3SLAM</a></h4><hr>
<h3 id="Anotation"><a href="#Anotation" class="headerlink" title="Anotation"></a><strong>Anotation</strong></h3><h4 id="Label-Studio"><a href="#Label-Studio" class="headerlink" title="Label Studio"></a><a href="https://towardsdatascience.com/introducing-label-studio-a-swiss-army-knife-of-data-labeling-140c1be92881" target="_blank" rel="noopener">Label Studio</a></h4><p>标注数据的瑞士军刀，网页版，可以标注检测、分类、分割、语音、自然语言处理的数据</p>
<h4 id="LATTE"><a href="#LATTE" class="headerlink" title="LATTE"></a><a href="https://github.com/bernwang/latte" target="_blank" rel="noopener">LATTE</a></h4><p>网页版半自动点云标注工具</p>
<h4 id="3D-BAT"><a href="#3D-BAT" class="headerlink" title="3D-BAT"></a><a href="https://github.com/walzimmer/3d-bat" target="_blank" rel="noopener">3D-BAT</a></h4><p>功能强大的3D点云标注工具</p>
<hr>
<h3 id="Simulation"><a href="#Simulation" class="headerlink" title="Simulation"></a><strong>Simulation</strong></h3><h4 id="Virtual-KITTI2-Dataset"><a href="#Virtual-KITTI2-Dataset" class="headerlink" title="Virtual KITTI2 Dataset"></a><a href="https://europe.naverlabs.com/research/computer-vision/proxy-virtual-worlds-vkitti-2/" target="_blank" rel="noopener">Virtual KITTI2 Dataset</a></h4><p>Unity仿真的KITTI格式数据集，包含分割，2D&amp;3D检测</p>
<hr>
<h3 id="CUDA"><a href="#CUDA" class="headerlink" title="CUDA"></a><strong>CUDA</strong></h3><h4 id="CUDA-Based-3D-data-Processing-Library"><a href="#CUDA-Based-3D-data-Processing-Library" class="headerlink" title="CUDA-Based 3D data Processing Library"></a><a href="https://github.com/neka-nat/cupoch" target="_blank" rel="noopener">CUDA-Based 3D data Processing Library</a></h4><p>c++ python点云处理实现，包含pcd加载，registeration，支持jetson平台</p>
<hr>
<h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a><strong>Datasets</strong></h3><h4 id="WoodScape"><a href="#WoodScape" class="headerlink" title="WoodScape"></a><a href="https://github.com/valeoai/WoodScape" target="_blank" rel="noopener">WoodScape</a></h4><p>Fisheye数据集，包含激光、GPS、IMU、4个Fisheye</p>
<h4 id="Argo"><a href="#Argo" class="headerlink" title="Argo"></a><a href="https://www.argoverse.org/data.html" target="_blank" rel="noopener">Argo</a></h4><p>Argo数据集，包含3D、tracking，地图信息丰富</p>
<h4 id="JackRabbot任务跟踪数据集"><a href="#JackRabbot任务跟踪数据集" class="headerlink" title="JackRabbot任务跟踪数据集"></a><a href="https://jrdb.stanford.edu/dataset/about" target="_blank" rel="noopener">JackRabbot任务跟踪数据集</a></h4><p>人物跟踪数据集，360全景图像，32线雷达</p>
<h4 id="A2D2"><a href="#A2D2" class="headerlink" title="A2D2"></a><a href="https://www.audi-electronics-venture.de/aev/web/en/driving-dataset.html" target="_blank" rel="noopener">A2D2</a></h4><p>奥迪发布自动驾驶数据集，包含2D语义分割，3D点云分割，3D边框</p>
<h4 id="BLVD"><a href="#BLVD" class="headerlink" title="BLVD"></a><a href="https://github.com/VCCIV/BLVD" target="_blank" rel="noopener">BLVD</a></h4><p>包含interactive event recognition和intention prediction的自动驾驶数据集</p>
<h4 id="ASTAR-3D"><a href="#ASTAR-3D" class="headerlink" title="ASTAR-3D"></a><a href="https://github.com/I2RDL2/ASTAR-3D" target="_blank" rel="noopener">ASTAR-3D</a></h4><p>An Autonomous Driving Dataset in Challeging Environments</p>
<h4 id="H3D"><a href="#H3D" class="headerlink" title="H3D"></a><a href="https://usa.honda-ri.com//H3D" target="_blank" rel="noopener">H3D</a></h4><p>本田自动驾驶数据集，包含3D BBox和tracking数据</p>
<h4 id="Toronto-3D"><a href="#Toronto-3D" class="headerlink" title="Toronto-3D"></a><a href="https://arxiv.org/abs/2003.08284" target="_blank" rel="noopener">Toronto-3D</a></h4><p>面向城市道路语义分割的大型移动激光雷达数据集</p>
<h4 id="DiDi"><a href="#DiDi" class="headerlink" title="DiDi"></a><a href="https://outreach.didichuxing.com/research/opendata/en/" target="_blank" rel="noopener">DiDi</a></h4><p>DiDi 2D目标检测数据集</p>
<h4 id="AVData"><a href="#AVData" class="headerlink" title="AVData"></a><a href="https://avdata.ford.com/" target="_blank" rel="noopener">AVData</a></h4><p>Ford AV Dataset<br><img src="/images/Awesome-Automative-Driving-Perception/Ford_AVDataset.jpg" alt=""></p>
<hr>
<h3 id="Calibration"><a href="#Calibration" class="headerlink" title="Calibration"></a><strong>Calibration</strong></h3><h4 id="多传感器自动标定"><a href="#多传感器自动标定" class="headerlink" title="多传感器自动标定"></a><a href="https://github.com/dzunigan/robot_autocalibration" target="_blank" rel="noopener">多传感器自动标定</a></h4><hr>
<h3 id="TOOLS"><a href="#TOOLS" class="headerlink" title="TOOLS"></a><strong>TOOLS</strong></h3><h4 id="Pytorch-Template"><a href="#Pytorch-Template" class="headerlink" title="Pytorch Template"></a><a href="https://github.com/L1aoXingyu/Deep-Learning-Project-Template" target="_blank" rel="noopener">Pytorch Template</a></h4><hr>
<h3 id="其它"><a href="#其它" class="headerlink" title="其它"></a><strong>其它</strong></h3><h4 id="Apollo3-0阅读笔记"><a href="#Apollo3-0阅读笔记" class="headerlink" title="Apollo3.0阅读笔记"></a><a href="https://github.com/YannZyl/Apollo-Note" target="_blank" rel="noopener">Apollo3.0阅读笔记</a></h4><h4 id="Pytorch分割损失函数集合"><a href="#Pytorch分割损失函数集合" class="headerlink" title="Pytorch分割损失函数集合"></a><a href="https://github.com/JunMa11/SegLoss" target="_blank" rel="noopener">Pytorch分割损失函数集合</a></h4><h4 id="牛逼的移动机器人底盘系统"><a href="#牛逼的移动机器人底盘系统" class="headerlink" title="牛逼的移动机器人底盘系统"></a><a href="https://github.com/nasa-jpl/open-source-rover" target="_blank" rel="noopener">牛逼的移动机器人底盘系统</a></h4><h4 id="TensorRT封装"><a href="#TensorRT封装" class="headerlink" title="TensorRT封装"></a><a href="https://github.com/zerollzeng/tiny-tensorrt" target="_blank" rel="noopener">TensorRT封装</a></h4><h4 id="手势指向"><a href="#手势指向" class="headerlink" title="手势指向"></a><a href="https://github.com/holli/hands_ai" target="_blank" rel="noopener">手势指向</a></h4><h4 id="Unity-ROS仿真工具"><a href="#Unity-ROS仿真工具" class="headerlink" title="Unity ROS仿真工具"></a><a href="https://github.com/mit-fast/FlightGoggles" target="_blank" rel="noopener">Unity ROS仿真工具</a></h4><h3 id="Lidar-Super-resolution"><a href="#Lidar-Super-resolution" class="headerlink" title="Lidar Super-resolution"></a><a href="https://github.com/RobustFieldAutonomyLab/lidar_super_resolution" target="_blank" rel="noopener">Lidar Super-resolution</a></h3><p>Simulation-based Lidar Super-resolution for Ground Vehicles</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%84%9F%E7%9F%A5/" rel="tag"># 感知</a>
              <a href="/tags/Awesome/" rel="tag"># Awesome</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/02/25/hexo-math/" rel="prev" title="如何HEXO中使用数学符号方法">
      <i class="fa fa-chevron-left"></i> 如何HEXO中使用数学符号方法
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Awesome系列"><span class="nav-number">1.</span> <span class="nav-text">Awesome系列</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Awesome-Autonomous-Vehicle"><span class="nav-number">1.1.</span> <span class="nav-text">Awesome Autonomous Vehicle</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Awesome-Point-Cloud-Analysis"><span class="nav-number">1.2.</span> <span class="nav-text">Awesome Point Cloud Analysis</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3D-Object-Detection"><span class="nav-number">1.3.</span> <span class="nav-text">3D Object Detection</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Awesome-NN-SLAM"><span class="nav-number">1.4.</span> <span class="nav-text">Awesome NN SLAM</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3D-Detection-base-on-Lidar"><span class="nav-number">2.</span> <span class="nav-text">3D Detection base on Lidar</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#PointPillars"><span class="nav-number">2.1.</span> <span class="nav-text">PointPillars
</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PointPillars-Fast-Encoders-for-Object-Detection-from-Point-Clouds"><span class="nav-number">2.2.</span> <span class="nav-text">PointPillars: Fast Encoders for Object Detection from Point Clouds</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Det3D"><span class="nav-number">2.3.</span> <span class="nav-text">Det3D</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#points3d"><span class="nav-number">2.4.</span> <span class="nav-text">points3d</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PointRCNN"><span class="nav-number">2.5.</span> <span class="nav-text">PointRCNN
</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PointNet系列"><span class="nav-number">2.6.</span> <span class="nav-text">PointNet系列</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PointNet"><span class="nav-number">2.7.</span> <span class="nav-text">PointNet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PointNet-1"><span class="nav-number">2.8.</span> <span class="nav-text">PointNet++</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PointNet-for-ScanNet"><span class="nav-number">2.9.</span> <span class="nav-text">PointNet++ for ScanNet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#TANet"><span class="nav-number">2.10.</span> <span class="nav-text">TANet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PIXOR"><span class="nav-number">2.11.</span> <span class="nav-text">PIXOR</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Complex-YOLO"><span class="nav-number">2.12.</span> <span class="nav-text">Complex-YOLO</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3D-IoU-Net"><span class="nav-number">2.13.</span> <span class="nav-text">3D IoU-Net</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3DSSD"><span class="nav-number">2.14.</span> <span class="nav-text">3DSSD</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SSN"><span class="nav-number">2.15.</span> <span class="nav-text">SSN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SA-SSD"><span class="nav-number">2.16.</span> <span class="nav-text">SA-SSD</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PV-RCNN"><span class="nav-number">2.17.</span> <span class="nav-text">PV-RCNN</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3D-Detection-base-on-Camera"><span class="nav-number">3.</span> <span class="nav-text">3D Detection base on Camera</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3D-Detection"><span class="nav-number">3.1.</span> <span class="nav-text">3D Detection</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#单目3D检测Mono3D"><span class="nav-number">3.2.</span> <span class="nav-text">单目3D检测Mono3D++</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Orthographic-3D-Object-Detection"><span class="nav-number">3.3.</span> <span class="nav-text">Orthographic 3D Object Detection</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#TLNet"><span class="nav-number">3.4.</span> <span class="nav-text">TLNet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SMOKE"><span class="nav-number">3.5.</span> <span class="nav-text">SMOKE</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2D-Detection"><span class="nav-number">4.</span> <span class="nav-text">2D Detection</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#mmdetection"><span class="nav-number">4.1.</span> <span class="nav-text">mmdetection</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SimpleDet"><span class="nav-number">4.2.</span> <span class="nav-text">SimpleDet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CenterNet"><span class="nav-number">4.3.</span> <span class="nav-text">CenterNet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ShuffleNet"><span class="nav-number">4.4.</span> <span class="nav-text">ShuffleNet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DenseBox"><span class="nav-number">4.5.</span> <span class="nav-text">DenseBox</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#EfficientDet"><span class="nav-number">4.6.</span> <span class="nav-text">EfficientDet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SSD系列"><span class="nav-number">4.7.</span> <span class="nav-text">SSD系列</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#YOLOv3系列"><span class="nav-number">4.8.</span> <span class="nav-text">YOLOv3系列</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Segmentation"><span class="nav-number">5.</span> <span class="nav-text">Segmentation</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Pytorch-Segmentation"><span class="nav-number">5.1.</span> <span class="nav-text">Pytorch Segmentation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Pytorch-Segmentation-Efficient"><span class="nav-number">5.2.</span> <span class="nav-text">Pytorch Segmentation-Efficient</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Pytorch-Segmentation-Fast"><span class="nav-number">5.3.</span> <span class="nav-text">Pytorch Segmentation-Fast</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Pytorch-Segmentation-Toolbox"><span class="nav-number">5.4.</span> <span class="nav-text">Pytorch Segmentation Toolbox</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Pytorch-Segmentation-1"><span class="nav-number">5.5.</span> <span class="nav-text">Pytorch Segmentation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Pytorch-Segmentation-2"><span class="nav-number">5.6.</span> <span class="nav-text">Pytorch Segmentation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Learning-Semantic-Boundaries-from-Noisy-Annotations"><span class="nav-number">5.7.</span> <span class="nav-text">Learning Semantic Boundaries from Noisy Annotations</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#LEDNet"><span class="nav-number">5.8.</span> <span class="nav-text">LEDNet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Fast-SCNN"><span class="nav-number">5.9.</span> <span class="nav-text">Fast-SCNN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#U-Net"><span class="nav-number">5.10.</span> <span class="nav-text">U-Net</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#YOLACT"><span class="nav-number">5.11.</span> <span class="nav-text">YOLACT</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CenterMask"><span class="nav-number">5.12.</span> <span class="nav-text">CenterMask</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Backbone"><span class="nav-number">6.</span> <span class="nav-text">Backbone</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#VoVNet"><span class="nav-number">6.1.</span> <span class="nav-text">VoVNet</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tracking"><span class="nav-number">7.</span> <span class="nav-text">Tracking</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3D-Mutli-Object-Tracking"><span class="nav-number">7.1.</span> <span class="nav-text">3D Mutli-Object Tracking</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Argo-Baseline-Tracking"><span class="nav-number">7.2.</span> <span class="nav-text">Argo Baseline Tracking</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DeepSort"><span class="nav-number">7.3.</span> <span class="nav-text">DeepSort</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Multi-Object-Tracking"><span class="nav-number">7.4.</span> <span class="nav-text">Multi Object Tracking</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Multi-Object-Tracking-in-Python-and-Pytorch"><span class="nav-number">7.5.</span> <span class="nav-text">Multi-Object Tracking in Python and Pytorch</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#FairMOT"><span class="nav-number">7.6.</span> <span class="nav-text">FairMOT</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Object-Detection-and-Tracking"><span class="nav-number">7.7.</span> <span class="nav-text">Object-Detection-and-Tracking</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SDVTracker"><span class="nav-number">7.8.</span> <span class="nav-text">SDVTracker</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Prediction"><span class="nav-number">8.</span> <span class="nav-text">Prediction</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#MotionNet"><span class="nav-number">8.1.</span> <span class="nav-text">MotionNet</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SLAM"><span class="nav-number">9.</span> <span class="nav-text">SLAM</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Point-Cloud-Registration"><span class="nav-number">9.1.</span> <span class="nav-text">Point Cloud Registration</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DeLS-3D"><span class="nav-number">9.2.</span> <span class="nav-text">DeLS-3D</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#NDT改进"><span class="nav-number">9.3.</span> <span class="nav-text">NDT改进</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SuMa"><span class="nav-number">9.4.</span> <span class="nav-text">SuMa++</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#BLAM"><span class="nav-number">9.5.</span> <span class="nav-text">BLAM</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SE3SLAM"><span class="nav-number">9.6.</span> <span class="nav-text">SE3SLAM</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Anotation"><span class="nav-number">10.</span> <span class="nav-text">Anotation</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Label-Studio"><span class="nav-number">10.1.</span> <span class="nav-text">Label Studio</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#LATTE"><span class="nav-number">10.2.</span> <span class="nav-text">LATTE</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3D-BAT"><span class="nav-number">10.3.</span> <span class="nav-text">3D-BAT</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Simulation"><span class="nav-number">11.</span> <span class="nav-text">Simulation</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Virtual-KITTI2-Dataset"><span class="nav-number">11.1.</span> <span class="nav-text">Virtual KITTI2 Dataset</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CUDA"><span class="nav-number">12.</span> <span class="nav-text">CUDA</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#CUDA-Based-3D-data-Processing-Library"><span class="nav-number">12.1.</span> <span class="nav-text">CUDA-Based 3D data Processing Library</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Datasets"><span class="nav-number">13.</span> <span class="nav-text">Datasets</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#WoodScape"><span class="nav-number">13.1.</span> <span class="nav-text">WoodScape</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Argo"><span class="nav-number">13.2.</span> <span class="nav-text">Argo</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#JackRabbot任务跟踪数据集"><span class="nav-number">13.3.</span> <span class="nav-text">JackRabbot任务跟踪数据集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#A2D2"><span class="nav-number">13.4.</span> <span class="nav-text">A2D2</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#BLVD"><span class="nav-number">13.5.</span> <span class="nav-text">BLVD</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ASTAR-3D"><span class="nav-number">13.6.</span> <span class="nav-text">ASTAR-3D</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#H3D"><span class="nav-number">13.7.</span> <span class="nav-text">H3D</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Toronto-3D"><span class="nav-number">13.8.</span> <span class="nav-text">Toronto-3D</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DiDi"><span class="nav-number">13.9.</span> <span class="nav-text">DiDi</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AVData"><span class="nav-number">13.10.</span> <span class="nav-text">AVData</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Calibration"><span class="nav-number">14.</span> <span class="nav-text">Calibration</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#多传感器自动标定"><span class="nav-number">14.1.</span> <span class="nav-text">多传感器自动标定</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TOOLS"><span class="nav-number">15.</span> <span class="nav-text">TOOLS</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Pytorch-Template"><span class="nav-number">15.1.</span> <span class="nav-text">Pytorch Template</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#其它"><span class="nav-number">16.</span> <span class="nav-text">其它</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Apollo3-0阅读笔记"><span class="nav-number">16.1.</span> <span class="nav-text">Apollo3.0阅读笔记</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Pytorch分割损失函数集合"><span class="nav-number">16.2.</span> <span class="nav-text">Pytorch分割损失函数集合</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#牛逼的移动机器人底盘系统"><span class="nav-number">16.3.</span> <span class="nav-text">牛逼的移动机器人底盘系统</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#TensorRT封装"><span class="nav-number">16.4.</span> <span class="nav-text">TensorRT封装</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#手势指向"><span class="nav-number">16.5.</span> <span class="nav-text">手势指向</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Unity-ROS仿真工具"><span class="nav-number">16.6.</span> <span class="nav-text">Unity ROS仿真工具</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Lidar-Super-resolution"><span class="nav-number">17.</span> <span class="nav-text">Lidar Super-resolution</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Xiaoxiao Yang"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Xiaoxiao Yang</p>
  <div class="site-description" itemprop="description">DuDuBiu的个人小站</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">6</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/idontlikelongname" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;idontlikelongname" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xiaoxiao Yang</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.1
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
